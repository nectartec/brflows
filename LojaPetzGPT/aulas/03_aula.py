
import streamlit as st
import openai

openai_key = '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'

def retorna_resposta_modelo(mensagens,
                            openai_key,
                            modelo='gpt-3.5-turbo',
                            temperatura=0,
                            stream=False):
    openai.api_key = openai_key
    response = openai.ChatCompletion.create(
        model=modelo,
        messages=mensagens,
        temperature=temperatura,
        stream=stream
    )
    return response

def pagina_principal():

    if not 'mensagens' in st.session_state:
        st.session_state.mensagens = []
    
    mensagens = st.session_state['mensagens']

    st.header('ðŸ¤– Asimov Chatbot', divider=True)

    for mensagem in mensagens:
        chat = st.chat_message(mensagem['role'])
        chat.markdown(mensagem['content'])
    
    prompt = st.chat_input('Fale com o chat')
    if prompt:
        nova_mensagem = {'role': 'user',
                         'content': prompt}
        chat = st.chat_message(nova_mensagem['role'])
        chat.markdown(nova_mensagem['content'])
        mensagens.append(nova_mensagem)

        chat = st.chat_message('assistant')
        placeholder = chat.empty()
        placeholder.markdown("â–Œ")
        resposta_completa = ''
        respostas = retorna_resposta_modelo(mensagens,
                                            openai_key,
                                            stream=True)
        for resposta in respostas:
            resposta_completa += resposta.choices[0].delta.get('content', '')
            placeholder.markdown(resposta_completa + "â–Œ")
        placeholder.markdown(resposta_completa)
        nova_mensagem = {'role': 'assistant',
                         'content': resposta_completa}
        mensagens.append(nova_mensagem)


        st.session_state['mensagens'] = mensagens




pagina_principal()
